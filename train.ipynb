{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597586841149",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 Physical GPUs, 1 Logical GPUs\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D, Dropout, Add, LeakyReLU, UpSampling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras import Sequential # Add Sequential\n",
    "import tensorflow as tf # for GPU set-up\n",
    "import os\n",
    "\n",
    "# Memory Allocation for GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training data shape: (240, 256, 256, 1)\nValidation data shape: (27, 256, 256, 1)\n"
    }
   ],
   "source": [
    "DATA_PATH = os.path.abspath(\"..\\\\..\\\\00_MLDL\\\\00_BreadBrother\\\\04_Image_Segmentation\\\\\") # Variable path\n",
    "\n",
    "x_train = np.load(os.path.join(DATA_PATH, \"dataset\\\\x_train.npy\"))\n",
    "y_train = np.load(os.path.join(DATA_PATH, \"dataset\\\\y_train.npy\"))\n",
    "x_val = np.load(os.path.join(DATA_PATH, \"dataset\\\\x_val.npy\"))\n",
    "y_val = np.load(os.path.join(DATA_PATH, \"dataset\\\\y_val.npy\"))\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Validation data shape: {x_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_27 (Conv2D)           (None, 256, 256, 32)      320       \n_________________________________________________________________\nmax_pooling2d_22 (MaxPooling (None, 128, 128, 32)      0         \n_________________________________________________________________\nconv2d_28 (Conv2D)           (None, 128, 128, 64)      18496     \n_________________________________________________________________\nmax_pooling2d_23 (MaxPooling (None, 64, 64, 64)        0         \n_________________________________________________________________\nconv2d_29 (Conv2D)           (None, 64, 64, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_24 (MaxPooling (None, 32, 32, 128)       0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 32, 32, 128)       16512     \n_________________________________________________________________\nup_sampling2d_4 (UpSampling2 (None, 64, 64, 128)       0         \n_________________________________________________________________\nconv2d_30 (Conv2D)           (None, 64, 64, 128)       147584    \n_________________________________________________________________\nup_sampling2d_5 (UpSampling2 (None, 128, 128, 128)     0         \n_________________________________________________________________\nconv2d_31 (Conv2D)           (None, 128, 128, 64)      73792     \n_________________________________________________________________\nup_sampling2d_6 (UpSampling2 (None, 256, 256, 64)      0         \n_________________________________________________________________\nconv2d_32 (Conv2D)           (None, 256, 256, 1)       577       \n=================================================================\nTotal params: 331,137\nTrainable params: 331,137\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Downsampling\n",
    "model.add(Conv2D(32, kernel_size=3, activation=\"relu\", padding=\"same\",  input_shape=(256, 256, 1)))\n",
    "model.add(MaxPooling2D(pool_size=2, padding=\"same\")) # Reduce feature map size\n",
    "model.add(Conv2D(64, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=2, padding=\"same\"))\n",
    "model.add(Conv2D(128, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=2, padding=\"same\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "# Upsampling\n",
    "model.add(UpSampling2D(size=2))\n",
    "model.add(Conv2D(128, kernel_size=3, activation=\"sigmoid\", padding=\"same\"))\n",
    "model.add(UpSampling2D(size=2))\n",
    "model.add(Conv2D(64, kernel_size=3, activation=\"sigmoid\", padding=\"same\"))\n",
    "model.add(UpSampling2D(size=2))\n",
    "model.add(Conv2D(1, kernel_size=3, activation=\"sigmoid\", padding=\"same\"))\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\", \"mse\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 240 samples, validate on 27 samples\nEpoch 1/100\n240/240 [==============================] - 8s 33ms/step - loss: 0.6109 - acc: 0.6860 - mse: 0.2036 - val_loss: 0.5069 - val_acc: 0.7626 - val_mse: 0.1626\nEpoch 2/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.4957 - acc: 0.7499 - mse: 0.1611 - val_loss: 0.4545 - val_acc: 0.7626 - val_mse: 0.1475\nEpoch 3/100\n240/240 [==============================] - 1s 5ms/step - loss: 0.4538 - acc: 0.7499 - mse: 0.1487 - val_loss: 0.4241 - val_acc: 0.7626 - val_mse: 0.1380\nEpoch 4/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.4281 - acc: 0.7501 - mse: 0.1400 - val_loss: 0.3944 - val_acc: 0.7629 - val_mse: 0.1291\nEpoch 5/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.4197 - acc: 0.7500 - mse: 0.1391 - val_loss: 0.4174 - val_acc: 0.7626 - val_mse: 0.1426\nEpoch 6/100\n240/240 [==============================] - 1s 5ms/step - loss: 0.3953 - acc: 0.7540 - mse: 0.1312 - val_loss: 0.3724 - val_acc: 0.7783 - val_mse: 0.1212\nEpoch 7/100\n240/240 [==============================] - 1s 5ms/step - loss: 0.3413 - acc: 0.8133 - mse: 0.1097 - val_loss: 0.3337 - val_acc: 0.8018 - val_mse: 0.1088\nEpoch 8/100\n240/240 [==============================] - 1s 5ms/step - loss: 0.3641 - acc: 0.7761 - mse: 0.1221 - val_loss: 0.3698 - val_acc: 0.7900 - val_mse: 0.1262\nEpoch 9/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.3312 - acc: 0.8193 - mse: 0.1045 - val_loss: 0.3064 - val_acc: 0.8318 - val_mse: 0.0893\nEpoch 10/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.3479 - acc: 0.7968 - mse: 0.1084 - val_loss: 0.3493 - val_acc: 0.7626 - val_mse: 0.1194\nEpoch 11/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.3573 - acc: 0.7733 - mse: 0.1195 - val_loss: 0.2970 - val_acc: 0.8475 - val_mse: 0.0949\nEpoch 12/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.3085 - acc: 0.8215 - mse: 0.0991 - val_loss: 0.3000 - val_acc: 0.8246 - val_mse: 0.0968\nEpoch 13/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.2887 - acc: 0.8399 - mse: 0.0904 - val_loss: 0.2597 - val_acc: 0.8268 - val_mse: 0.0847\nEpoch 14/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.2740 - acc: 0.8439 - mse: 0.0879 - val_loss: 0.2287 - val_acc: 0.8657 - val_mse: 0.0693\nEpoch 15/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.2585 - acc: 0.8702 - mse: 0.0770 - val_loss: 0.2710 - val_acc: 0.8429 - val_mse: 0.0840\nEpoch 16/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.2458 - acc: 0.8693 - mse: 0.0740 - val_loss: 0.2177 - val_acc: 0.9263 - val_mse: 0.0614\nEpoch 17/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.2426 - acc: 0.8769 - mse: 0.0717 - val_loss: 0.2102 - val_acc: 0.8619 - val_mse: 0.0630\nEpoch 18/100\n240/240 [==============================] - 1s 5ms/step - loss: 0.2019 - acc: 0.8971 - mse: 0.0582 - val_loss: 0.1532 - val_acc: 0.9424 - val_mse: 0.0410\nEpoch 19/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.1689 - acc: 0.9177 - mse: 0.0465 - val_loss: 0.1076 - val_acc: 0.9425 - val_mse: 0.0274\nEpoch 20/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.1133 - acc: 0.9385 - mse: 0.0285 - val_loss: 0.0744 - val_acc: 0.9516 - val_mse: 0.0183\nEpoch 21/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.1902 - acc: 0.9081 - mse: 0.0524 - val_loss: 0.1847 - val_acc: 0.8885 - val_mse: 0.0596\nEpoch 22/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.1616 - acc: 0.9079 - mse: 0.0463 - val_loss: 0.0921 - val_acc: 0.9543 - val_mse: 0.0220\nEpoch 23/100\n240/240 [==============================] - 1s 4ms/step - loss: 0.1100 - acc: 0.9410 - mse: 0.0273 - val_loss: 0.0674 - val_acc: 0.9556 - val_mse: 0.0155\nEpoch 24/100\n240/240 [==============================] - 1s 5ms/step - loss: 0.0949 - acc: 0.9458 - mse: 0.0228 - val_loss: 0.0596 - val_acc: 0.9575 - val_mse: 0.0138\nEpoch 25/100\n240/240 [==============================] - 1s 5ms/step - loss: 0.0877 - acc: 0.9483 - mse: 0.0208 - val_loss: 0.0574 - val_acc: 0.9576 - val_mse: 0.0133\nEpoch 26/100\n240/240 [==============================] - 1s 5ms/step - loss: 0.0834 - acc: 0.9495 - mse: 0.0197 - val_loss: 0.0634 - val_acc: 0.9546 - val_mse: 0.0158\nEpoch 27/100\n240/240 [==============================] - 1s 6ms/step - loss: 0.0798 - acc: 0.9507 - mse: 0.0186 - val_loss: 0.0685 - val_acc: 0.9526 - val_mse: 0.0167\nEpoch 28/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0796 - acc: 0.9507 - mse: 0.0183 - val_loss: 0.0550 - val_acc: 0.9592 - val_mse: 0.0128\nEpoch 29/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0789 - acc: 0.9509 - mse: 0.0183 - val_loss: 0.0527 - val_acc: 0.9589 - val_mse: 0.0118\nEpoch 30/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0818 - acc: 0.9496 - mse: 0.0194 - val_loss: 0.0491 - val_acc: 0.9608 - val_mse: 0.0110\nEpoch 31/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0751 - acc: 0.9526 - mse: 0.0171 - val_loss: 0.0465 - val_acc: 0.9614 - val_mse: 0.0101\nEpoch 32/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0717 - acc: 0.9534 - mse: 0.0162 - val_loss: 0.0450 - val_acc: 0.9619 - val_mse: 0.0097\nEpoch 33/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0674 - acc: 0.9550 - mse: 0.0149 - val_loss: 0.0513 - val_acc: 0.9586 - val_mse: 0.0119\nEpoch 34/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0727 - acc: 0.9529 - mse: 0.0165 - val_loss: 0.0435 - val_acc: 0.9621 - val_mse: 0.0092\nEpoch 35/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0652 - acc: 0.9558 - mse: 0.0142 - val_loss: 0.0424 - val_acc: 0.9624 - val_mse: 0.0089\nEpoch 36/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0656 - acc: 0.9552 - mse: 0.0144 - val_loss: 0.0503 - val_acc: 0.9590 - val_mse: 0.0115\nEpoch 37/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0644 - acc: 0.9560 - mse: 0.0141 - val_loss: 0.0546 - val_acc: 0.9572 - val_mse: 0.0129\nEpoch 38/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0742 - acc: 0.9522 - mse: 0.0169 - val_loss: 0.0401 - val_acc: 0.9628 - val_mse: 0.0082\nEpoch 39/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0677 - acc: 0.9543 - mse: 0.0150 - val_loss: 0.0405 - val_acc: 0.9625 - val_mse: 0.0083\nEpoch 40/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0726 - acc: 0.9525 - mse: 0.0164 - val_loss: 0.0484 - val_acc: 0.9604 - val_mse: 0.0110\nEpoch 41/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0656 - acc: 0.9550 - mse: 0.0146 - val_loss: 0.0385 - val_acc: 0.9629 - val_mse: 0.0079\nEpoch 42/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0599 - acc: 0.9567 - mse: 0.0127 - val_loss: 0.0380 - val_acc: 0.9629 - val_mse: 0.0078\nEpoch 43/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0580 - acc: 0.9574 - mse: 0.0121 - val_loss: 0.0402 - val_acc: 0.9616 - val_mse: 0.0085\nEpoch 44/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0597 - acc: 0.9569 - mse: 0.0125 - val_loss: 0.0378 - val_acc: 0.9633 - val_mse: 0.0075\nEpoch 45/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0584 - acc: 0.9573 - mse: 0.0122 - val_loss: 0.0378 - val_acc: 0.9628 - val_mse: 0.0077\nEpoch 46/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0585 - acc: 0.9566 - mse: 0.0126 - val_loss: 0.0364 - val_acc: 0.9636 - val_mse: 0.0073\nEpoch 47/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0601 - acc: 0.9559 - mse: 0.0130 - val_loss: 0.0383 - val_acc: 0.9630 - val_mse: 0.0079\nEpoch 48/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0729 - acc: 0.9520 - mse: 0.0165 - val_loss: 0.0596 - val_acc: 0.9556 - val_mse: 0.0143\nEpoch 49/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0993 - acc: 0.9406 - mse: 0.0259 - val_loss: 0.0611 - val_acc: 0.9576 - val_mse: 0.0132\nEpoch 50/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0831 - acc: 0.9512 - mse: 0.0198 - val_loss: 0.0432 - val_acc: 0.9621 - val_mse: 0.0093\nEpoch 51/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0638 - acc: 0.9561 - mse: 0.0139 - val_loss: 0.0407 - val_acc: 0.9625 - val_mse: 0.0084\nEpoch 52/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0597 - acc: 0.9571 - mse: 0.0126 - val_loss: 0.0384 - val_acc: 0.9631 - val_mse: 0.0079\nEpoch 53/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0585 - acc: 0.9575 - mse: 0.0123 - val_loss: 0.0384 - val_acc: 0.9635 - val_mse: 0.0077\nEpoch 54/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0591 - acc: 0.9567 - mse: 0.0126 - val_loss: 0.0449 - val_acc: 0.9591 - val_mse: 0.0097\nEpoch 55/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0559 - acc: 0.9576 - mse: 0.0116 - val_loss: 0.0353 - val_acc: 0.9637 - val_mse: 0.0069\nEpoch 56/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0551 - acc: 0.9581 - mse: 0.0112 - val_loss: 0.0357 - val_acc: 0.9632 - val_mse: 0.0071\nEpoch 57/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0562 - acc: 0.9574 - mse: 0.0117 - val_loss: 0.0350 - val_acc: 0.9638 - val_mse: 0.0069\nEpoch 58/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0567 - acc: 0.9576 - mse: 0.0118 - val_loss: 0.0356 - val_acc: 0.9636 - val_mse: 0.0070\nEpoch 59/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0612 - acc: 0.9551 - mse: 0.0136 - val_loss: 0.0523 - val_acc: 0.9576 - val_mse: 0.0120\nEpoch 60/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0575 - acc: 0.9566 - mse: 0.0123 - val_loss: 0.0401 - val_acc: 0.9615 - val_mse: 0.0082\nEpoch 61/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0583 - acc: 0.9562 - mse: 0.0127 - val_loss: 0.0354 - val_acc: 0.9634 - val_mse: 0.0071\nEpoch 62/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0572 - acc: 0.9572 - mse: 0.0122 - val_loss: 0.0410 - val_acc: 0.9622 - val_mse: 0.0090\nEpoch 63/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0588 - acc: 0.9564 - mse: 0.0126 - val_loss: 0.0355 - val_acc: 0.9636 - val_mse: 0.0070\nEpoch 64/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0530 - acc: 0.9585 - mse: 0.0108 - val_loss: 0.0334 - val_acc: 0.9640 - val_mse: 0.0063\nEpoch 65/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0504 - acc: 0.9590 - mse: 0.0100 - val_loss: 0.0341 - val_acc: 0.9636 - val_mse: 0.0065\nEpoch 66/100\n240/240 [==============================] - 2s 7ms/step - loss: 0.0503 - acc: 0.9592 - mse: 0.0101 - val_loss: 0.0346 - val_acc: 0.9635 - val_mse: 0.0070\nEpoch 67/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0499 - acc: 0.9595 - mse: 0.0100 - val_loss: 0.0518 - val_acc: 0.9545 - val_mse: 0.0126\nEpoch 68/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0719 - acc: 0.9514 - mse: 0.0163 - val_loss: 0.0509 - val_acc: 0.9586 - val_mse: 0.0119\nEpoch 69/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0640 - acc: 0.9563 - mse: 0.0138 - val_loss: 0.0390 - val_acc: 0.9634 - val_mse: 0.0080\nEpoch 70/100\n240/240 [==============================] - 2s 6ms/step - loss: 0.0541 - acc: 0.9586 - mse: 0.0112 - val_loss: 0.0376 - val_acc: 0.9635 - val_mse: 0.0080\nEpoch 71/100\n240/240 [==============================] - 2s 10ms/step - loss: 0.0541 - acc: 0.9585 - mse: 0.0110 - val_loss: 0.0339 - val_acc: 0.9632 - val_mse: 0.0068\nEpoch 72/100\n240/240 [==============================] - 2s 9ms/step - loss: 0.0522 - acc: 0.9585 - mse: 0.0106 - val_loss: 0.0349 - val_acc: 0.9629 - val_mse: 0.0070\nEpoch 73/100\n240/240 [==============================] - 2s 9ms/step - loss: 0.0516 - acc: 0.9585 - mse: 0.0107 - val_loss: 0.0383 - val_acc: 0.9622 - val_mse: 0.0080\nEpoch 74/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0495 - acc: 0.9593 - mse: 0.0099 - val_loss: 0.0343 - val_acc: 0.9637 - val_mse: 0.0066\n\nEpoch 00074: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\nEpoch 75/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0487 - acc: 0.9594 - mse: 0.0097 - val_loss: 0.0326 - val_acc: 0.9640 - val_mse: 0.0061\nEpoch 76/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0476 - acc: 0.9599 - mse: 0.0093 - val_loss: 0.0323 - val_acc: 0.9641 - val_mse: 0.0060\nEpoch 77/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0479 - acc: 0.9598 - mse: 0.0093 - val_loss: 0.0318 - val_acc: 0.9642 - val_mse: 0.0059\nEpoch 78/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0473 - acc: 0.9598 - mse: 0.0093 - val_loss: 0.0315 - val_acc: 0.9643 - val_mse: 0.0059\nEpoch 79/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0478 - acc: 0.9598 - mse: 0.0094 - val_loss: 0.0321 - val_acc: 0.9640 - val_mse: 0.0061\nEpoch 80/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0495 - acc: 0.9587 - mse: 0.0101 - val_loss: 0.0324 - val_acc: 0.9642 - val_mse: 0.0061\nEpoch 81/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0488 - acc: 0.9595 - mse: 0.0097 - val_loss: 0.0324 - val_acc: 0.9640 - val_mse: 0.0060\nEpoch 82/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0470 - acc: 0.9599 - mse: 0.0092 - val_loss: 0.0313 - val_acc: 0.9642 - val_mse: 0.0058\nEpoch 83/100\n240/240 [==============================] - 2s 9ms/step - loss: 0.0457 - acc: 0.9605 - mse: 0.0088 - val_loss: 0.0316 - val_acc: 0.9641 - val_mse: 0.0059\nEpoch 84/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0460 - acc: 0.9603 - mse: 0.0089 - val_loss: 0.0306 - val_acc: 0.9644 - val_mse: 0.0057\nEpoch 85/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0456 - acc: 0.9605 - mse: 0.0088 - val_loss: 0.0316 - val_acc: 0.9641 - val_mse: 0.0060\nEpoch 86/100\n240/240 [==============================] - 3s 12ms/step - loss: 0.0452 - acc: 0.9606 - mse: 0.0087 - val_loss: 0.0306 - val_acc: 0.9643 - val_mse: 0.0058\nEpoch 87/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0455 - acc: 0.9606 - mse: 0.0087 - val_loss: 0.0317 - val_acc: 0.9640 - val_mse: 0.0060\nEpoch 88/100\n240/240 [==============================] - 2s 8ms/step - loss: 0.0452 - acc: 0.9606 - mse: 0.0087 - val_loss: 0.0306 - val_acc: 0.9643 - val_mse: 0.0057\nEpoch 89/100\n 64/240 [=======>......................] - ETA: 1s - loss: 0.0281 - acc: 0.9647 - mse: 0.0051"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-b38c0580d2d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=32, callbacks=[\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m ])\n",
      "\u001b[1;32m~\\anaconda3\\envs\\peakdetection\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\peakdetection\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3800\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3801\u001b[0m         expand_composites=True)\n\u001b[0;32m   3802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3800\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3801\u001b[0m         expand_composites=True)\n\u001b[0;32m   3802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=32, callbacks=[\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor = 0.2, patience=10, verbose=1, mode=\"auto\", min_lr=1e-05)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 7))\n",
    "\n",
    "ax[0, 0].set_title('loss')\n",
    "ax[0, 0].plot(history.history['loss'], 'r')\n",
    "ax[0, 1].set_title('acc')\n",
    "ax[0, 1].plot(history.history['acc'], 'b')\n",
    "\n",
    "ax[1, 0].set_title('val_loss')\n",
    "ax[1, 0].plot(history.history['val_loss'], 'r--')\n",
    "ax[1, 1].set_title('val_acc')\n",
    "ax[1, 1].plot(history.history['val_acc'], 'b--')"
   ]
  }
 ]
}